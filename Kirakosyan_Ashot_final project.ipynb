{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cd2a27b-9374-435a-999c-d824f60b8c57",
   "metadata": {},
   "source": [
    "## Final Project Report(CS634)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b4d1f-0a14-45aa-9288-829ac725443c",
   "metadata": {},
   "source": [
    "Name - Ashot Kirakosyan<br>\n",
    "NJIT ID - ak2095<br>\n",
    "Email - ak2995@njit.edu<br>\n",
    "Date: 11/24/2024<br>\n",
    "Professor - Yasser Abduallah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ab88e-7f8d-4b01-8afa-3a08b58fcc7a",
   "metadata": {},
   "source": [
    "### Model Evaluation Report for Breast Cancer Recurrence Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea987b-5009-4120-965f-353e8576e14c",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ddcba-24e9-44f3-994f-e0945a66d94d",
   "metadata": {},
   "source": [
    "In this report, we evaluate and compare the performance of three different machine learning models—Random Forest, Decision Tree, and GRU (Gated Recurrent Unit)—on the task of predicting breast cancer recurrence. The dataset used for this analysis is the Breast Cancer Recurrence dataset from the UCI Machine Learning Repository. This dataset contains several features of breast cancer patients and their recurrence status, which are classified as either \"no recurrence\" or \"recurrence\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2382a-0867-4eed-9db8-e305b7b1d4b0",
   "metadata": {},
   "source": [
    "### Data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2db82-5d2c-46d7-927c-e5b927a81fe2",
   "metadata": {},
   "source": [
    "The dataset used in this analysis was downloaded from the UCI Machine Learning Repository, specifically from the Breast Cancer Recurrence dataset. The dataset was retrieved using the fetch_ucirepo function, which facilitates the direct access to UCI datasets for use in machine learning experiments.<br>\n",
    "\n",
    "Here’s a brief description of the source: <br>\n",
    "\n",
    "1. Dataset Name: Breast Cancer Recurrence\n",
    "2. Source: UCI Machine Learning Repository https://archive.ics.uci.edu/dataset/14/breast+cancer\n",
    "3. ID: 14 (Identifier for the dataset in the UCI repository)\n",
    "4. The data consists of features related to breast cancer patients and their recurrence status, which is classified as either \"no recurrence\" or \"recurrence\". This dataset has been widely used for testing machine learning algorithms in medical data classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c922aa3-6d88-43b3-bcde-58c1a2aca3ac",
   "metadata": {},
   "source": [
    "### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2292e0-ac8c-49ca-807f-2624bcb1d118",
   "metadata": {},
   "source": [
    "1. The features of the dataset were one-hot encoded, and categorical labels were converted to numeric format for the models. <br>\n",
    "2. The target labels were further transformed into one-hot encoded format for use in the GRU model. <br>\n",
    "3. Additionally, the features were reshaped to fit the input format expected by the GRU model, which requires a 3D input tensor of the shape (samples, time steps, features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004f3ef-292b-4869-a17c-819cbbf8c5a7",
   "metadata": {},
   "source": [
    "### Download repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dcbb63-6ea4-4146-91e8-6e7fd70ac408",
   "metadata": {},
   "source": [
    "Link to the repository https://github.com/Ash-K-97/Kirakosyan_Ashot_Final_Project<br>\n",
    "Download the zip file and extract all files into one folder<BR>\n",
    "Read a readme file and follow the instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceeb4cb-7a77-4c5b-b435-75ef387ca57f",
   "metadata": {},
   "source": [
    "### Cross-validation Setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b182edb6-6681-42a7-922c-e6a596b83704",
   "metadata": {},
   "source": [
    "For each model, 10-fold stratified cross-validation was performed, ensuring that each fold contains a proportional distribution of the target classes. This helps to avoid overfitting and provides a reliable evaluation of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c79ca4-2b06-4bfc-b211-5c7f38ed78d9",
   "metadata": {},
   "source": [
    "### Evaluation Metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab2e0f-c3e2-4f48-99bc-e9b97180a247",
   "metadata": {},
   "source": [
    "1. Confusion Matrix (TP, TN, FP, FN): To measure the number of true positives, true negatives, false positives, and false negatives.\n",
    "2. Accuracy (ACC): The proportion of correctly classified instances.\n",
    "3. True Positive Rate (TPR), Specificity (SPC), Positive Predictive Value (PPV), Negative Predictive Value (NPV), and other advanced metrics that assess the model's ability to predict both positive and negative cases accurately.\n",
    "4. F1 Score: A balanced measure of precision and recall.\n",
    "5. ROC AUC: The area under the receiver operating characteristic curve, which is a measure of the model's ability to distinguish between the classes.\n",
    "6. Brier Score: A measure of the accuracy of probabilistic predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a470a-d2b1-41fb-a637-3d00188de448",
   "metadata": {},
   "source": [
    "### Model 1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32dfcd2-4785-44bb-a4bf-0d326420ec34",
   "metadata": {},
   "source": [
    "The Random Forest Classifier is an ensemble method that uses multiple decision trees to make predictions. It is known for its robustness and ability to handle high-dimensional data with various feature types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9791c3-eacd-4d7f-b0d5-de54935bc848",
   "metadata": {},
   "source": [
    "### Model 2: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb767f5-7067-4e5e-844f-cb5dac8b785e",
   "metadata": {},
   "source": [
    "The Decision Tree Classifier is a simpler model compared to Random Forest, but it can still provide insightful results, especially when the data has a clear hierarchical structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b62ea-d0f3-4e35-af4f-a922882e81db",
   "metadata": {},
   "source": [
    "### Model 3: GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0670307-318f-468d-af18-79810888d722",
   "metadata": {},
   "source": [
    "The GRU model is a type of recurrent neural network designed for sequential data. Even though this task is not inherently sequential, using GRU allows us to test the performance of a deep learning model in a more complex setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d3186-51d7-4a10-81ef-d0c3a07e769e",
   "metadata": {},
   "source": [
    "### Software Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0798d50-1bf5-4317-9358-f4fe8c7dd6d5",
   "metadata": {},
   "source": [
    "1. Python: Version 3.6 or higher (Recommended: Python 3.8+)<br>\n",
    "   Ensure that Python is installed on your system. You can download it from python.org.<br>\n",
    "2. TensorFlow: Version 2.x (For the GRU model)\n",
    "   TensorFlow is required to build and train the GRU model. You can install TensorFlow using:\n",
    " \n",
    "   pip install tensorflow command in your Cmd (forWindowss) or the Terminal application for macOSs/Linux)\n",
    "3. Scikit-learn: Version 0.24 or higher (For the Random Forest, Decision Tree, and metrics)\n",
    "    Scikit-learn is necessary for machine learning models and evaluation metrics. Install it using:\n",
    "\n",
    "    pip install scikit-learn\n",
    "4. Pandas: Version 1.x or higher (For data manipulation and processing)\n",
    "   Pandas is used to handle and process the dataset. Install it using: \n",
    "\n",
    "    pip install pandas\n",
    "5. NumPy: Version 1.19 or higher (For numerical operations)\n",
    "    NumPy is essential for efficient numerical computations. Install it using:\n",
    "\n",
    "    pip install numpy\n",
    "\n",
    "6. UCI ML Repo: To fetch datasets from the UCI Machine Learning Repository\n",
    "   You need the ucimlrepo library to fetch datasets from the UCI repository:\n",
    "\n",
    "    pip install ucimlrepo\n",
    "7. IPython: (For displaying DataFrames in Jupyter notebooks)\n",
    "    You need the IPython library for displaying data in Jupyter:\n",
    "\n",
    "   pip install ipython\n",
    "8. Jupyter Notebook (Optional, but recommended for interactive work)\n",
    "    Install Jupyter using:\n",
    "\n",
    "    pip install notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2057295e-6d8f-438d-867d-7e6e8554939a",
   "metadata": {},
   "source": [
    "### Hardware Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2dc8f5-f6a4-44c7-a5e2-a81f06636f04",
   "metadata": {},
   "source": [
    "1. CPU: Any modern processor should suffice. However, for deep learning (GRU model), it's recommended to use a machine with a GPU.\n",
    "2. RAM: At least 8 GB of RAM is recommended, particularly for handling large datasets and training deep learning models.\n",
    "3. GPU: If running the GRU model on a large dataset, having an NVIDIA GPU is highly recommended for faster training. You can use TensorFlow with GPU support for acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143edc0-e0fa-4d50-a50e-e5fb217386d6",
   "metadata": {},
   "source": [
    "### How to Run the Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd76631a-b3a5-42c6-86a7-ba083425bb20",
   "metadata": {},
   "source": [
    "1. After downloading the repository and extracting the files move it to the directory of your choice<br>\n",
    "2. Run the Program: In the CLI, navigate to the directory containing the script and execute:<br>\n",
    "    .Example: cd C:\\Users\\YourName\\Documents\\Kirakosyan_Ashot.Final_Project<br>\n",
    "    .where: YourName is the name of the user.<br>\n",
    "3. After code execution, you should be in the directory of the file <br>\n",
    "4. You can check which Python files are in this directory by using the following command: dir <br>\n",
    "5. Once you see the Python file you want to run, you can execute it by typing: python Kirakosyan_Ashot_Final_code.py<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d3ee2-a11f-469f-87ce-2570bca17053",
   "metadata": {},
   "source": [
    "### Below is the running code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fd1dd7-3b69-4532-80fc-ff888247c786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Fold-wise Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SPC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BS</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>BACC</th>\n",
       "      <th>BSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.592262</td>\n",
       "      <td>0.592262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.536111</td>\n",
       "      <td>0.536111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.536111</td>\n",
       "      <td>0.536111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.072222</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.536111</td>\n",
       "      <td>0.536111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TP  TN  FP  FN       TPR       SPC       PPV       NPV       FPR       FDR  \\\n",
       "0   3  17   4   5  0.375000  0.809524  0.428571  0.772727  0.190476  0.571429   \n",
       "1   2  17   3   7  0.222222  0.850000  0.400000  0.708333  0.150000  0.600000   \n",
       "2   2  17   3   7  0.222222  0.850000  0.400000  0.708333  0.150000  0.600000   \n",
       "3   2  17   3   7  0.222222  0.850000  0.400000  0.708333  0.150000  0.600000   \n",
       "4   0  17   3   9  0.000000  0.850000  0.000000  0.653846  0.150000  1.000000   \n",
       "5   3  18   2   6  0.333333  0.900000  0.600000  0.750000  0.100000  0.400000   \n",
       "6   5  19   1   3  0.625000  0.950000  0.833333  0.863636  0.050000  0.166667   \n",
       "7   3  20   0   5  0.375000  1.000000  1.000000  0.800000  0.000000  0.000000   \n",
       "8   3  18   2   5  0.375000  0.900000  0.600000  0.782609  0.100000  0.400000   \n",
       "9   5  16   4   3  0.625000  0.800000  0.555556  0.842105  0.200000  0.444444   \n",
       "\n",
       "        FNR       ACC        F1        BS       TSS       HSS      BACC  \\\n",
       "0  0.625000  0.689655  0.400000  0.310345  0.184524  0.379310  0.592262   \n",
       "1  0.777778  0.655172  0.285714  0.344828  0.072222  0.310345  0.536111   \n",
       "2  0.777778  0.655172  0.285714  0.344828  0.072222  0.310345  0.536111   \n",
       "3  0.777778  0.655172  0.285714  0.344828  0.072222  0.310345  0.536111   \n",
       "4  1.000000  0.586207  0.000000  0.413793 -0.150000  0.172414  0.425000   \n",
       "5  0.666667  0.724138  0.428571  0.275862  0.233333  0.448276  0.616667   \n",
       "6  0.375000  0.857143  0.714286  0.142857  0.575000  0.714286  0.787500   \n",
       "7  0.625000  0.821429  0.545455  0.178571  0.375000  0.642857  0.687500   \n",
       "8  0.625000  0.750000  0.461538  0.250000  0.275000  0.500000  0.637500   \n",
       "9  0.375000  0.750000  0.588235  0.250000  0.425000  0.500000  0.712500   \n",
       "\n",
       "        BSS  \n",
       "0  0.592262  \n",
       "1  0.536111  \n",
       "2  0.536111  \n",
       "3  0.536111  \n",
       "4  0.425000  \n",
       "5  0.616667  \n",
       "6  0.787500  \n",
       "7  0.687500  \n",
       "8  0.637500  \n",
       "9  0.712500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Random Forest Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SPC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BS</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>BACC</th>\n",
       "      <th>BSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.8</td>\n",
       "      <td>17.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>0.875952</td>\n",
       "      <td>0.521746</td>\n",
       "      <td>0.758992</td>\n",
       "      <td>0.124048</td>\n",
       "      <td>0.478254</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.714409</td>\n",
       "      <td>0.399523</td>\n",
       "      <td>0.285591</td>\n",
       "      <td>0.213452</td>\n",
       "      <td>0.428818</td>\n",
       "      <td>0.606726</td>\n",
       "      <td>0.606726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TP    TN   FP   FN     TPR       SPC       PPV       NPV       FPR  \\\n",
       "0  2.8  17.6  2.5  5.7  0.3375  0.875952  0.521746  0.758992  0.124048   \n",
       "\n",
       "        FDR     FNR       ACC        F1        BS       TSS       HSS  \\\n",
       "0  0.478254  0.6625  0.714409  0.399523  0.285591  0.213452  0.428818   \n",
       "\n",
       "       BACC       BSS  \n",
       "0  0.606726  0.606726  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC: 0.68\n",
      "Average Brier Score: 0.20\n",
      "Decision Tree Fold-wise Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SPC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BS</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>BACC</th>\n",
       "      <th>BSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.184524</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.592262</td>\n",
       "      <td>0.592262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.572222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TP  TN  FP  FN       TPR       SPC       PPV       NPV       FPR       FDR  \\\n",
       "0   3  17   4   5  0.375000  0.809524  0.428571  0.772727  0.190476  0.571429   \n",
       "1   4  14   6   5  0.444444  0.700000  0.400000  0.736842  0.300000  0.600000   \n",
       "2   6  15   5   3  0.666667  0.750000  0.545455  0.833333  0.250000  0.454545   \n",
       "3   4  14   6   5  0.444444  0.700000  0.400000  0.736842  0.300000  0.600000   \n",
       "4   0  15   5   9  0.000000  0.750000  0.000000  0.625000  0.250000  1.000000   \n",
       "5   4  14   6   5  0.444444  0.700000  0.400000  0.736842  0.300000  0.600000   \n",
       "6   5  16   4   3  0.625000  0.800000  0.555556  0.842105  0.200000  0.444444   \n",
       "7   4  17   3   4  0.500000  0.850000  0.571429  0.809524  0.150000  0.428571   \n",
       "8   6  15   5   2  0.750000  0.750000  0.545455  0.882353  0.250000  0.454545   \n",
       "9   5  16   4   3  0.625000  0.800000  0.555556  0.842105  0.200000  0.444444   \n",
       "\n",
       "        FNR       ACC        F1        BS       TSS       HSS      BACC  \\\n",
       "0  0.625000  0.689655  0.400000  0.310345  0.184524  0.379310  0.592262   \n",
       "1  0.555556  0.620690  0.421053  0.379310  0.144444  0.241379  0.572222   \n",
       "2  0.333333  0.724138  0.600000  0.275862  0.416667  0.448276  0.708333   \n",
       "3  0.555556  0.620690  0.421053  0.379310  0.144444  0.241379  0.572222   \n",
       "4  1.000000  0.517241  0.000000  0.482759 -0.250000  0.034483  0.375000   \n",
       "5  0.555556  0.620690  0.421053  0.379310  0.144444  0.241379  0.572222   \n",
       "6  0.375000  0.750000  0.588235  0.250000  0.425000  0.500000  0.712500   \n",
       "7  0.500000  0.750000  0.533333  0.250000  0.350000  0.500000  0.675000   \n",
       "8  0.250000  0.750000  0.631579  0.250000  0.500000  0.500000  0.750000   \n",
       "9  0.375000  0.750000  0.588235  0.250000  0.425000  0.500000  0.712500   \n",
       "\n",
       "        BSS  \n",
       "0  0.592262  \n",
       "1  0.572222  \n",
       "2  0.708333  \n",
       "3  0.572222  \n",
       "4  0.375000  \n",
       "5  0.572222  \n",
       "6  0.712500  \n",
       "7  0.675000  \n",
       "8  0.750000  \n",
       "9  0.712500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Decision Tree Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SPC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BS</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>BACC</th>\n",
       "      <th>BSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.1</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.760952</td>\n",
       "      <td>0.440202</td>\n",
       "      <td>0.781767</td>\n",
       "      <td>0.239048</td>\n",
       "      <td>0.559798</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.67931</td>\n",
       "      <td>0.460454</td>\n",
       "      <td>0.32069</td>\n",
       "      <td>0.248452</td>\n",
       "      <td>0.358621</td>\n",
       "      <td>0.624226</td>\n",
       "      <td>0.624226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TP    TN   FP   FN     TPR       SPC       PPV       NPV       FPR  \\\n",
       "0  4.1  15.3  4.8  4.4  0.4875  0.760952  0.440202  0.781767  0.239048   \n",
       "\n",
       "        FDR     FNR      ACC        F1       BS       TSS       HSS      BACC  \\\n",
       "0  0.559798  0.5125  0.67931  0.460454  0.32069  0.248452  0.358621  0.624226   \n",
       "\n",
       "        BSS  \n",
       "0  0.624226  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC: 0.63\n",
      "Average Brier Score: 0.32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464ms/step\n",
      "GRU Fold-wise Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SPC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BS</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>BACC</th>\n",
       "      <th>BSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.077381</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.538690</td>\n",
       "      <td>0.538690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.172222</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0.586111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TP  TN  FP  FN       TPR       SPC       PPV       NPV       FPR       FDR  \\\n",
       "0   1  20   1   7  0.125000  0.952381  0.500000  0.740741  0.047619  0.500000   \n",
       "1   0  20   0   9  0.000000  1.000000  0.000000  0.689655  0.000000  0.000000   \n",
       "2   2  19   1   7  0.222222  0.950000  0.666667  0.730769  0.050000  0.333333   \n",
       "3   3  18   2   6  0.333333  0.900000  0.600000  0.750000  0.100000  0.400000   \n",
       "4   0  18   2   9  0.000000  0.900000  0.000000  0.666667  0.100000  1.000000   \n",
       "5   3  20   0   6  0.333333  1.000000  1.000000  0.769231  0.000000  0.000000   \n",
       "6   4  19   1   4  0.500000  0.950000  0.800000  0.826087  0.050000  0.200000   \n",
       "7   0  20   0   8  0.000000  1.000000  0.000000  0.714286  0.000000  0.000000   \n",
       "8   2  20   0   6  0.250000  1.000000  1.000000  0.769231  0.000000  0.000000   \n",
       "9   5  16   4   3  0.625000  0.800000  0.555556  0.842105  0.200000  0.444444   \n",
       "\n",
       "        FNR       ACC        F1        BS       TSS       HSS      BACC  \\\n",
       "0  0.875000  0.724138  0.200000  0.275862  0.077381  0.448276  0.538690   \n",
       "1  1.000000  0.689655  0.000000  0.310345  0.000000  0.379310  0.500000   \n",
       "2  0.777778  0.724138  0.333333  0.275862  0.172222  0.448276  0.586111   \n",
       "3  0.666667  0.724138  0.428571  0.275862  0.233333  0.448276  0.616667   \n",
       "4  1.000000  0.620690  0.000000  0.379310 -0.100000  0.241379  0.450000   \n",
       "5  0.666667  0.793103  0.500000  0.206897  0.333333  0.586207  0.666667   \n",
       "6  0.500000  0.821429  0.615385  0.178571  0.450000  0.642857  0.725000   \n",
       "7  1.000000  0.714286  0.000000  0.285714  0.000000  0.428571  0.500000   \n",
       "8  0.750000  0.785714  0.400000  0.214286  0.250000  0.571429  0.625000   \n",
       "9  0.375000  0.750000  0.588235  0.250000  0.425000  0.500000  0.712500   \n",
       "\n",
       "        BSS  \n",
       "0  0.538690  \n",
       "1  0.500000  \n",
       "2  0.586111  \n",
       "3  0.616667  \n",
       "4  0.450000  \n",
       "5  0.666667  \n",
       "6  0.725000  \n",
       "7  0.500000  \n",
       "8  0.625000  \n",
       "9  0.712500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average GRU Metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TPR</th>\n",
       "      <th>SPC</th>\n",
       "      <th>PPV</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>ACC</th>\n",
       "      <th>F1</th>\n",
       "      <th>BS</th>\n",
       "      <th>TSS</th>\n",
       "      <th>HSS</th>\n",
       "      <th>BACC</th>\n",
       "      <th>BSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.238889</td>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.512222</td>\n",
       "      <td>0.749877</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.287778</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>0.734729</td>\n",
       "      <td>0.306552</td>\n",
       "      <td>0.265271</td>\n",
       "      <td>0.184127</td>\n",
       "      <td>0.469458</td>\n",
       "      <td>0.592063</td>\n",
       "      <td>0.592063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TP    TN   FP   FN       TPR       SPC       PPV       NPV       FPR  \\\n",
       "0  2.0  19.0  1.1  6.5  0.238889  0.945238  0.512222  0.749877  0.054762   \n",
       "\n",
       "        FDR       FNR       ACC        F1        BS       TSS       HSS  \\\n",
       "0  0.287778  0.761111  0.734729  0.306552  0.265271  0.184127  0.469458   \n",
       "\n",
       "       BACC       BSS  \n",
       "0  0.592063  0.592063  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy (GRU): 0.73\n",
      "Average ROC AUC (GRU): 0.67\n",
      "Average Brier Score (GRU): 0.19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, brier_score_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from IPython.display import display  \n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Only modify stdout if not running in a Jupyter notebook environment\n",
    "if not \"ipykernel\" in sys.modules:\n",
    "    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n",
    "    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')\n",
    "\n",
    "# Set TensorFlow logging level to avoid unnecessary logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow log messages\n",
    "\n",
    "# Suppress warnings that may arise\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fetch the dataset\n",
    "def fetch_data():\n",
    "    breast_cancer = fetch_ucirepo(id=14)\n",
    "    X = pd.DataFrame(breast_cancer.data.features)\n",
    "    y = breast_cancer.data.targets\n",
    "    \n",
    "    # One-hot encode categorical features in X\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    X_encoded = pd.DataFrame(encoder.fit_transform(X), columns=encoder.get_feature_names_out(X.columns))\n",
    "    \n",
    "    # Encode the target variable y\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y).ravel()  # Convert to 0 and 1 for classification\n",
    "    y_categorical = to_categorical(y_encoded)  # One-hot encoding for GRU model\n",
    "    \n",
    "    # Reshape X for GRU (samples, time steps, features)\n",
    "    X_reshaped = X_encoded.values.reshape((X_encoded.shape[0], 1, X_encoded.shape[1]))\n",
    "    \n",
    "    return X_encoded, y_encoded, y_categorical, X_reshaped\n",
    "\n",
    "X_encoded, y_encoded, y_categorical, X_reshaped = fetch_data()\n",
    "\n",
    "# Function to calculate various metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TP, TN, FP, FN = cm[1, 1], cm[0, 0], cm[0, 1], cm[1, 0]\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    epsilon = 1e-10  # Small epsilon to avoid division by zero\n",
    "    TPR = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    SPC = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    PPV = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    NPV = TN / (TN + FN) if (TN + FN) != 0 else 0\n",
    "    FPR = FP / (FP + TN) if (FP + TN) != 0 else 0\n",
    "    FDR = FP / (FP + TP) if (FP + TP) != 0 else 0\n",
    "    FNR = FN / (FN + TP) if (FN + TP) != 0 else 0\n",
    "    ACC = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) != 0 else 0\n",
    "    F1 = 2 * (PPV * TPR) / (PPV + TPR + epsilon)\n",
    "    # Skill Scores\n",
    "    TSS = TPR + SPC - 1\n",
    "    HSS = (TP + TN - (FP + FN)) / (TP + TN + FP + FN) if (TP + TN + FP + FN) != 0 else 0\n",
    "    BACC = (TPR + SPC) / 2 if (TPR + SPC) != 0 else 0\n",
    "    BSS = (TPR + SPC) / 2 if (TPR + SPC) != 0 else 0\n",
    "    BS = brier_score_loss(y_true, y_pred)\n",
    "    return {\n",
    "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN, 'TPR': TPR, 'SPC': SPC,\n",
    "        'PPV': PPV, 'NPV': NPV, 'FPR': FPR, 'FDR': FDR, 'FNR': FNR, 'ACC': ACC,\n",
    "        'F1': F1, 'BS': BS, 'TSS': TSS, 'HSS': HSS, 'BACC' : BACC, 'BSS' : BSS,\n",
    "    }\n",
    "\n",
    "# Cross-validation function\n",
    "def cross_validate_model(model, X, y, reshaped=False):\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "    roc_auc_scores = []\n",
    "    brier_scores = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Reshape X for GRU if necessary\n",
    "        if reshaped:\n",
    "            X_train, X_test = X_train.reshape((X_train.shape[0], 1, X_train.shape[1])), X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(y_test, y_pred)\n",
    "        fold_metrics.append(metrics)\n",
    "        \n",
    "        # ROC AUC\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "        # Brier Score\n",
    "        brier_score = brier_score_loss(y_test, y_pred_prob)\n",
    "        brier_scores.append(brier_score)\n",
    "    \n",
    "    avg_metrics = {key: np.mean([fold[key] for fold in fold_metrics]) for key in fold_metrics[0].keys()}\n",
    "    avg_roc_auc = np.mean(roc_auc_scores)\n",
    "    avg_brier_score = np.mean(brier_scores)\n",
    "    \n",
    "    return fold_metrics, avg_metrics, avg_roc_auc, avg_brier_score\n",
    "\n",
    "# Training and evaluation functions for different models\n",
    "\n",
    "def train_random_forest():\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    fold_metrics_rf, avg_metrics_rf, avg_roc_auc_rf, avg_brier_rf = cross_validate_model(rf, X_encoded.values, y_encoded)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Random Forest Fold-wise Metrics:\")\n",
    "    display(pd.DataFrame(fold_metrics_rf))\n",
    "    print(\"Average Random Forest Metrics:\")\n",
    "    display(pd.DataFrame([avg_metrics_rf]))\n",
    "    print(f\"Average ROC AUC: {avg_roc_auc_rf:.2f}\")\n",
    "    print(f\"Average Brier Score: {avg_brier_rf:.2f}\")\n",
    "\n",
    "def train_decision_tree():\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    fold_metrics_dt, avg_metrics_dt, avg_roc_auc_dt, avg_brier_dt = cross_validate_model(dt, X_encoded.values, y_encoded)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Decision Tree Fold-wise Metrics:\")\n",
    "    display(pd.DataFrame(fold_metrics_dt))\n",
    "    print(\"Average Decision Tree Metrics:\")\n",
    "    display(pd.DataFrame([avg_metrics_dt]))\n",
    "    print(f\"Average ROC AUC: {avg_roc_auc_dt:.2f}\")\n",
    "    print(f\"Average Brier Score: {avg_brier_dt:.2f}\")\n",
    "\n",
    "def train_gru():\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    fold_metrics_gru = []\n",
    "    accuracy_scores_gru = []\n",
    "    roc_auc_scores_gru = []\n",
    "    brier_scores_gru = []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_reshaped, y_encoded), 1):\n",
    "        X_train, X_test = X_reshaped[train_idx], X_reshaped[test_idx]\n",
    "        y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "        \n",
    "        # Convert target to one-hot encoding for GRU\n",
    "        y_train_categorical = to_categorical(y_train)\n",
    "        y_test_categorical = to_categorical(y_test)\n",
    "        \n",
    "        # Define GRU model\n",
    "        model_gru = Sequential([\n",
    "            Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "            GRU(50, return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            GRU(50),\n",
    "            Dropout(0.2),\n",
    "            Dense(y_train_categorical.shape[1], activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        # Train GRU model\n",
    "        model_gru.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_data=(X_test, y_test_categorical), verbose=0)\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred_prob_gru = model_gru.predict(X_test)\n",
    "        y_pred_gru = np.argmax(y_pred_prob_gru, axis=1)\n",
    "        y_test_labels_gru = np.argmax(y_test_categorical, axis=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(y_test_labels_gru, y_pred_gru)\n",
    "        fold_metrics_gru.append(metrics)\n",
    "        \n",
    "        # Accuracy, ROC AUC, and Brier Score\n",
    "        accuracy_scores_gru.append(accuracy_score(y_test_labels_gru, y_pred_gru))\n",
    "        roc_auc_scores_gru.append(roc_auc_score(y_test_labels_gru, y_pred_prob_gru[:, 1]))\n",
    "        brier_scores_gru.append(brier_score_loss(y_test_labels_gru, y_pred_prob_gru[:, 1]))\n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_metrics_gru = {key: np.mean([fold[key] for fold in fold_metrics_gru]) for key in fold_metrics_gru[0].keys()}\n",
    "    avg_accuracy_gru = np.mean(accuracy_scores_gru)\n",
    "    avg_roc_auc_gru = np.mean(roc_auc_scores_gru)\n",
    "    avg_brier_score_gru = np.mean(brier_scores_gru)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"GRU Fold-wise Metrics:\")\n",
    "    display(pd.DataFrame(fold_metrics_gru))\n",
    "    print(\"Average GRU Metrics:\")\n",
    "    display(pd.DataFrame([avg_metrics_gru]))\n",
    "    print(f\"Average Accuracy (GRU): {avg_accuracy_gru:.2f}\")\n",
    "    print(f\"Average ROC AUC (GRU): {avg_roc_auc_gru:.2f}\")\n",
    "    print(f\"Average Brier Score (GRU): {avg_brier_score_gru:.2f}\")\n",
    "\n",
    "# Call functions to train and evaluate all models\n",
    "train_random_forest()\n",
    "train_decision_tree()\n",
    "train_gru()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fc74b-b28a-4b15-9105-d8406f564611",
   "metadata": {},
   "source": [
    "### Random forest results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3785a7-9876-438f-9a3b-cc9a23c1a254",
   "metadata": {},
   "source": [
    "1. Accuracy (ACC): 71.44%\n",
    "2. TPR (Recall): 33.75%\n",
    "3. SPC (Specificity): 87.60%\n",
    "4. F1 Score: 0.40\n",
    "5. ROC AUC: 0.68\n",
    "6. Brier Score: 0.20<br>\n",
    "\n",
    "The Random Forest model shows a reasonable performance with 71.44% accuracy. However, it struggles with recall (33.75%), which means it misses a significant proportion of actual recurrence events (positive cases). The model does well in identifying negative cases (specificity of 87.6%) and has a moderate F1 score of 0.40, suggesting a low balance between precision and recall.\n",
    "The ROC AUC score of 0.68 indicates moderate ability to discriminate between the two classes, while the Brier score of 0.20 shows that its predicted probabilities are somewhat reliable but not perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ced3c-5e67-4927-8878-4641a6b9e13e",
   "metadata": {},
   "source": [
    "### Decision tree model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe07a422-9b22-4ae2-ba48-b81dfd27dfcc",
   "metadata": {},
   "source": [
    "1. Accuracy (ACC): 67.93%\n",
    "2. TPR (Recall): 48.75%\n",
    "3. SPC (Specificity): 76.10%\n",
    "4. F1 Score: 0.46\n",
    "5. ROC AUC: 0.63\n",
    "6. Brier Score: 0.32 <br>\n",
    "\n",
    "The Decision Tree model has 67.93% accuracy, which is lower than the Random Forest. However, it has a higher recall (48.75%), meaning it is better at identifying positive cases (recurrence events) compared to Random Forest, though still not perfect. Its F1 score of 0.46 is slightly better than that of Random Forest, showing an improved balance between precision and recall.\n",
    "\n",
    "The specificity is also lower (76.10%) compared to Random Forest, indicating that the model is not as good at correctly identifying negative cases (no recurrence events). The ROC AUC score of 0.63 suggests that its ability to discriminate between the two classes is weaker than that of Random Forest, and the Brier score of 0.32 indicates that its predicted probabilities are less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df0e59a-3f75-41bf-86f8-faaf34cb560e",
   "metadata": {},
   "source": [
    "### GRU results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7eba3-fbc5-4839-aec2-5436b9b145c5",
   "metadata": {},
   "source": [
    "1. Accuracy (ACC): 73.47%\n",
    "2. TPR (Recall): 23.89%\n",
    "3. SPC (Specificity): 94.52%\n",
    "4. F1 Score: 0.31\n",
    "5. ROC AUC: 0.67\n",
    "6. Brier Score: 0.19 <br>\n",
    "\n",
    "The GRU model shows the highest accuracy (73.47%), indicating its overall correct predictions are slightly better than both Random Forest and Decision Tree. However, the recall is still quite low (23.89%), meaning it misses a significant portion of the recurrence events (positive cases). The F1 score of 0.31 reflects this imbalance, with the model favoring precision over recall. Its specificity is the highest (94.52%), meaning it is particularly good at identifying negative cases (no recurrence events).\n",
    "\n",
    "The ROC AUC score of 0.67 is similar to Random Forest, indicating that the GRU model also has a moderate ability to distinguish between the two classes. The Brier score of 0.19 is the lowest of all three models, suggesting that its predicted probabilities are the most accurate among the three.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab35ba7-faaa-4f05-9abf-f4c176558928",
   "metadata": {},
   "source": [
    "### Comparison and Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8155a65-98e0-4770-9942-2e558e8c0c78",
   "metadata": {},
   "source": [
    "##### Best Performing Algorithm: Random Forest <br>\n",
    "\n",
    "While each model has its strengths and weaknesses, the Random Forest algorithm appears to be the best-performing model overall, particularly in terms of a balance between sensitivity (recall) and specificity. Although it struggles with recall (33.75%), it has:<br>\n",
    "\n",
    "1. A higher accuracy (71.44%) compared to Decision Tree (67.93%) and GRU (73.47%).\n",
    "2. The best balance between Precision (PPV = 52.17%) and recall (TPR = 33.75%).\n",
    "3. A moderate F1 score of 0.40, which is better than GRU's 0.31.\n",
    "4. High specificity (87.6%), which is important in imbalanced datasets.\n",
    "5. While Random Forest is not perfect, it provides a better overall balance for both classes than the Decision Tree and GRU models, which exhibit higher recall but suffer from imbalanced results and weaker performance in other areas (like specificity and F1 score).\n",
    "\n",
    "##### Decision Tree vs. GRU <br>\n",
    "Decision Tree performs better in recall (48.75%) compared to GRU (23.89%), but at the cost of lower specificity (76.10% vs. GRU's 94.52%). This indicates that the Decision Tree is more biased towards identifying positive cases, but also generates more false positives.\n",
    "GRU has the highest accuracy (73.47%) but suffers from very low recall and a poor F1 score (0.31). Despite its high specificity, it misses many of the actual recurrence events, making it less effective in identifying positive instances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194d522-721b-4ea9-bdb5-bf3a65d79d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
